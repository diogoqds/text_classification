{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/PythonEnviroments/developing-fun/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/dev/PythonEnviroments/developing-fun/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/home/dev/PythonEnviroments/developing-fun/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-*- coding: utf-8 -*- Created on Fri 21 2020\n",
    "@author: Thiago Pinho\n",
    "@colaborators: Thiago Russo, Emmanuel Perotto\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, plot_confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import spacy\n",
    "from spacy.lang.pt import Portuguese\n",
    "from spacy.lang.pt.stop_words import STOP_WORDS\n",
    "from unidecode import unidecode\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from string import punctuation\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from preprocessing import generate_freq_dist_plot, generate_wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "For better code management, the constants used in this notebook will be listed bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_MODEL_NAME = \"pt_core_news_sm\"\n",
    "RELATIVE_PATH_TO_FOLDER = \"./assets/datasets/ribon/\"\n",
    "DATA_FILENAME = \"feeds_label\"\n",
    "NLP_SPACY = spacy.load(VECTOR_MODEL_NAME)\n",
    "TARGET_VARIABLE = \"LABEL_TRAIN\"\n",
    "POSSIBLE_TEXT_VARIABLES = [\"CONTENT\", \"TITLE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data and start to treat the it's structure\n",
    "We'll have a first look at the raw data and after analysing it's structure we can fix missing values(By dropping or artificially inserting then). We can encode or adjust categorical data if needed, fix column names and also drop unnused colummns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  load the dataset \"\"\"\n",
    "relative_path_file = RELATIVE_PATH_TO_FOLDER + DATA_FILENAME + \".csv\"\n",
    "df_ribon_news = pd.read_csv(relative_path_file)\n",
    "print(df_ribon_news.info())\n",
    "print()\n",
    "print(df_ribon_news['Label_Train'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Based on the previous step it's possible to notice two things:\n",
    "\n",
    "1) First is that the column labels are not all uppercase or lowercase. \n",
    "\n",
    "2) The categories avaiable to classify are not all in the same case either which could lead to later confunsion on the real number of categories the model should classify.\n",
    "\n",
    "So we will fix by making: \n",
    "\n",
    "1) All **column names** will be **uppercase**\n",
    "\n",
    "2) All **target categories** will also be **uppercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"  Preprocessing the dataset names and values \"\"\"\n",
    "df_ribon_news.columns = map(lambda x: str(x).upper(), df_ribon_news.columns)\n",
    "\"\"\" Converting all labels in TARGET_VARIABLE to uppercase \"\"\"\n",
    "df_ribon_news[TARGET_VARIABLE] = df_ribon_news[TARGET_VARIABLE].str.upper()\n",
    "print(\"Column names are now: \", df_ribon_news.columns.to_list())\n",
    "print()\n",
    "print(TARGET_VARIABLE + \" categories are now: \", df_ribon_news[TARGET_VARIABLE].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing partial progress\n",
    "One of the advantages of jupyter notebook is the possibility of only repeating parts of the code when there is need for it. So let's store our partial progress for more stability and less rework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Let\"s store the data \"\"\"\n",
    "excel_filename = RELATIVE_PATH_TO_FOLDER + DATA_FILENAME + \"_treated.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Convert the dataframe to an xlsx file \"\"\"\n",
    "df_ribon_news.to_excel(excel_filename)\n",
    "\n",
    "print(\"Stored tread dataset on \", excel_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and analyse treated data\n",
    "Now we have treated some structural characteristics of the data and some details, let's analyse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"  Load the data for stability \"\"\"\n",
    "df_ribon_news_treated = pd.read_excel(excel_filename, index_col=0)\n",
    "print(df_ribon_news_treated.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label distribution, oversampling and undersampling\n",
    "One important step is to analyse how the target categories are distributed. That's useful so we can better partition our data, maybe apply some over or undersampling if it's necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_ribon_news_treated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-64b700b4941a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"  Let\"s see how the labels are distributed \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_labels_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ribon_news_treated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTARGET_VARIABLE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_labels_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maverage_samples_per_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_labels_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstandard_deviation_for_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_labels_count\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_ribon_news_treated' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"  Let\"s see how the labels are distributed \"\"\"\n",
    "data_labels_count = df_ribon_news_treated[TARGET_VARIABLE].value_counts()\n",
    "data_labels = data_labels_count.index\n",
    "average_samples_per_label = data_labels_count.mean()\n",
    "standard_deviation_for_labels = data_labels_count.std()\n",
    "print(\n",
    "    \"Mean number of samples for the target variable is: \",\n",
    "    average_samples_per_label)\n",
    "print(\n",
    "    \"Standard deviation number of samples for the target variable is: \",\n",
    "    standard_deviation_for_labels)\n",
    "\n",
    "''' Numerical analysis\n",
    "    One way to analyse the frequency of certain labels is to notice with\n",
    "    they're too afar from the other labels frequencies average. Let's use\n",
    "    standard deviation to check it'''\n",
    "def is_it_further_than_std_deviations( value ):\n",
    "    is_too_much = value > average_samples_per_label + standard_deviation_for_labels\n",
    "    is_too_little = value < average_samples_per_label - standard_deviation_for_labels\n",
    "    if is_too_much or is_too_little:\n",
    "        message = \"Warning\"\n",
    "    else:\n",
    "        message = \"Okay\"\n",
    "\n",
    "    return message\n",
    "\n",
    "for i in tqdm(range(0, len(data_labels), 2)):\n",
    "    even_indexed_label = data_labels[i]\n",
    "    odd_indexed_label = data_labels[i+1]\n",
    "\n",
    "    print(\"{0:20}  {1:10} {2:15} {3:20} {4:10} {5:10}\".format(\n",
    "        even_indexed_label, data_labels_count[even_indexed_label], is_it_further_than_std_deviations(data_labels_count[even_indexed_label]),\n",
    "        odd_indexed_label, data_labels_count[odd_indexed_label], is_it_further_than_std_deviations(data_labels_count[odd_indexed_label])))\n",
    "\n",
    "''' Visual plotting'''\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "sns.barplot(\n",
    "    x=data_labels_count.index,\n",
    "    y=data_labels_count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Based on the previous step, we can see the categories **ECOLOGIA** and **SOLIDARIEDADE** have **more than the average added by the standard deviation** which can cause the model to overly recognise those labels patterns and make then too sensitive for those. \n",
    "\n",
    "On other hand we have the categories **FAMILIA**, **CRIANCAS** and **IDOSOS** with **less than the average subtracted by the standard deviation** which can make the model too specific for those and hardly classify as it.\n",
    "\n",
    "For now, let's try oversampling the least common labels by grouping then. When our pipeline is finely tunned we can use the grouped labels as input for another pipeline trainned only to discern among those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' One possible approach is to group up under represented labels and further\n",
    "    analyse it in other pipeline.  '''\n",
    "data_labels_count = df_ribon_news_treated[TARGET_VARIABLE].value_counts()\n",
    "data_labels = data_labels_count.index\n",
    "under_represented_labels = [\n",
    "    scarse_label\n",
    "    for scarse_label in tqdm(data_labels)\n",
    "    if data_labels_count[scarse_label] < average_samples_per_label - standard_deviation_for_labels]\n",
    "print(under_represented_labels)\n",
    "\n",
    "''' Now we have found which ones are under represented we'll create a new\n",
    "    DataFrame changing the under represented to OUTROS '''\n",
    "GROUP_TARGET_LABEL = 'SCARCE_GROUP'\n",
    "df_ribon_news_grouped = df_ribon_news_treated.replace({TARGET_VARIABLE: under_represented_labels}, GROUP_TARGET_LABEL)\n",
    "print(df_ribon_news_grouped[TARGET_VARIABLE].value_counts())\n",
    "\n",
    "\"\"\"  Let\"s see how the labels are distributed \"\"\"\n",
    "data_labels_count = df_ribon_news_grouped[TARGET_VARIABLE].value_counts()\n",
    "data_labels = data_labels_count.index\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "sns.barplot(\n",
    "    x=data_labels_count.index,\n",
    "    y=data_labels_count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Storing partial progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_filename = RELATIVE_PATH_TO_FOLDER + DATA_FILENAME +\\\n",
    "    \"_treated_grouped.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Let\"s store the  data \"\"\"\n",
    "df_ribon_news_grouped.to_excel(excel_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Partition\n",
    "Now we have treated the data structure and sampling problems. Let's drop unwanted columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"  We then load the data for stability \"\"\"\n",
    "df_data = pd.read_excel(excel_filename, index_col=0)\n",
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" As we have two possible text_variables, let's choose one for first analysis \"\"\"\n",
    "text_variable = POSSIBLE_TEXT_VARIABLES[0]\n",
    "\"\"\" Dropping unwanted columns \"\"\"\n",
    "df_data = df_data[ [text_variable] + [TARGET_VARIABLE]]\n",
    "print(df_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing values\n",
    "As there are some samples without content, they'll not be useful to train or to validate the model. \n",
    "Hapilly they're not many so let's drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data = df_data.dropna()\n",
    "print(df_data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Parsing(Preprocessing)\n",
    "\n",
    "Before we train the model, it's necessary to tokenize words, find their lemmas and discard some words that could mislead the model.\n",
    "\n",
    "Let's take a first look at the text variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_column = df_data[text_variable]\n",
    "generate_wordcloud(raw_text_column)\n",
    "print(generate_freq_dist_plot(raw_text_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbols and stopwords\n",
    "\n",
    "As we can see, we have a lot of tokens from text variable being symbols or words that don't have by themselves much meaning. Let's fix that.\n",
    "We can also strip trailing spaces and remove multiple spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords_set = set(STOP_WORDS).union(set(stopwords.words('portuguese')))\n",
    "stopword_pattern = r'\\b(?:{})\\b'.format(r'|'.join(stopwords_set))\n",
    "symbols_pattern = '[^\\w\\s]'\n",
    "space_pattern = r'\\s{2,}'\n",
    "print(\"This is the stopword set: \", stopword_pattern)\n",
    "print()\n",
    "print(\"This is the symbols pattern: \", symbols_pattern)\n",
    "print(\"This is the space pattern:\", space_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Processing text on caracteres level'''\n",
    "df_data['PREPROCESSED_TEXT'] = df_data[text_variable].str.lower()\n",
    "df_data['PREPROCESSED_TEXT'] = df_data['PREPROCESSED_TEXT'].str.replace(\n",
    "    stopword_pattern, \"\")\n",
    "df_data['PREPROCESSED_TEXT'] = df_data['PREPROCESSED_TEXT'].str.replace(\n",
    "    symbols_pattern, \"\")\n",
    "df_data['PREPROCESSED_TEXT'] = df_data['PREPROCESSED_TEXT'].str.replace(\n",
    "    space_pattern, \" \")\n",
    "df_data['PREPROCESSED_TEXT'] = df_data['PREPROCESSED_TEXT'].str.strip()\n",
    "generate_wordcloud(df_data['PREPROCESSED_TEXT'])\n",
    "print(generate_freq_dist_plot(df_data['PREPROCESSED_TEXT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Now the most common words are way more expressive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing and stemming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessed_text_data = df_data['PREPROCESSED_TEXT'].to_list()\n",
    "''' Not all variables are being undestood as strings so we have to force it'''\n",
    "\n",
    "sentencizer = NLP_SPACY.create_pipe('sentencizer')\n",
    "''' Create the pipeline 'sentencizer' component '''\n",
    "\n",
    "try:\n",
    "    ''' We then add the component to the pipeline if we hadn't done before '''\n",
    "    NLP_SPACY.add_pipe(sentencizer, before='parser')\n",
    "except ValueError:\n",
    "    print(\"Pipe already present.\")\n",
    "\n",
    "print(NLP_SPACY.pipe_names)\n",
    "\n",
    "lemmatized_doc = []\n",
    "tokenized_data = []\n",
    "for row in tqdm(preprocessed_text_data):\n",
    "    doc = NLP_SPACY(row)\n",
    "    tokenized_data.append(doc)\n",
    "    lemmatized_doc.append(\" \".join([word.lemma_ if word.tag != \"PRONOUN\" else \"\" for word in doc ]))\n",
    "    \n",
    "df_data['LEMMATIZED_DOC'] = lemmatized_doc\n",
    "\n",
    "generate_wordcloud(df_data['LEMMATIZED_DOC'])\n",
    "print(generate_freq_dist_plot(df_data['LEMMATIZED_DOC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Recognition\n",
    "Some parts of speech may mislead the model associating classes to certain entities that are not really related to the categories.\n",
    "The NER model(spacy portuguese) we are using uses the following labels:\n",
    "\n",
    "| TYPE | DESCRIPTION |\n",
    "|------|-------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| PER | Named person or family. |\n",
    "| LOC | Name of politically or geographically defined location (cities, provinces, countries, international regions, bodies of water, mountains). |\n",
    "| ORG | Named corporate, governmental, or other organizational entity. |\n",
    "| MISC | Miscellaneous entities, e.g. events, nationalities, products or works of art. |\n",
    "\n",
    "Let's take a look at the named persons or families"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' First we take a look at the found entities'''\n",
    "entities_lists = []\n",
    "\n",
    "for docs in tokenized_data:\n",
    "    entities_text = \"\"\n",
    "    for entity in docs.ents:\n",
    "        if entity.label_ == \"PER\":\n",
    "            entities_text += \" \" + entity.text\n",
    "    entities_text = entities_text.strip()\n",
    "    entities_lists.append(entities_text)\n",
    "            \n",
    "df_data['ENTITIES'] = entities_lists\n",
    "generate_wordcloud(df_data['ENTITIES'])\n",
    "print(generate_freq_dist_plot(df_data['ENTITIES']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_set = set()\n",
    "entities_set = set([ word for word_list in list(map(list, df_data['ENTITIES'].str.split(\" \")))\n",
    "                            for word in word_list ])\n",
    "entities_set.remove(\"\")\n",
    "entities_pattern = r'\\b(?:{})\\b'.format('|'.join(entities_set)) \n",
    "\n",
    "''' Processing text on entity level'''\n",
    "df_data['PROCESSED_DOC'] = df_data['LEMMATIZED_DOC'].str.replace(entities_pattern, \"\")\n",
    "generate_wordcloud(df_data['PROCESSED_DOC'])\n",
    "print(generate_freq_dist_plot(df_data['PROCESSED_DOC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing partial progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Let\"s store the data \"\"\"\n",
    "excel_filename = RELATIVE_PATH_TO_FOLDER + DATA_FILENAME +\\\n",
    "    \"_preprocessed_data.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.to_excel(excel_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Text Filter(Counting and vectorizing)\n",
    " Now we have clear tokens we can measure how much they affect the outcome prediction and how many of them exist in each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  We then load the data for stability \"\"\"\n",
    "df_processed_data = pd.read_excel(excel_filename, index_col=0)\n",
    "print(df_processed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Best parameter using GridSearch (CV score=0.535):\n",
    "{'clf__alpha': 1e-05, 'clf__max_iter': 80, 'clf__penalty': 'l2', 'tfidf__norm': 'l1',\n",
    "'tfidf__use_idf': True, 'vect__max_df': 0.5, 'vect__max_features': None, 'vect__ngram_range': (1, 2)}\n",
    "'''\n",
    "''' Text Parser\n",
    "    This part is responsible to give weights to important tokens and remove\n",
    "    weight for unwanted ones or those who can be misguiding.\n",
    "    - Frequency Counter\n",
    "    - Id-IdF Counter\n",
    "'''\n",
    "count_vectorizer = CountVectorizer(\n",
    "    max_features=None, max_df=0.5, ngram_range=(1, 2))\n",
    "tfidf_transformer = TfidfTransformer(norm='l1', use_idf='True')\n",
    "\n",
    "''' Let's transform the lemmatized documents into count vectors '''\n",
    "count_vectors = count_vectorizer.fit_transform(\n",
    "    df_processed_data['PROCESSED_DOC'])\n",
    "\n",
    "''' Then use those count vectors to generate frequency vectors '''\n",
    "frequency_vectors = tfidf_transformer.fit_transform(count_vectors)\n",
    "\n",
    "print(count_vectors[0])\n",
    "print(frequency_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Model Train and Evaluation\n",
    "'''\n",
    "\n",
    "clf = SGDClassifier(alpha=1e-05, max_iter=80, penalty='l2')\n",
    "pipeline_simple = Pipeline([\n",
    "    ('clf', clf)\n",
    "])\n",
    "pipeline = Pipeline([\n",
    "    ('count_vectorizer', count_vectorizer),\n",
    "    ('tfidf_transformer', tfidf_transformer),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "''' Let's use cross validation to better evaluate models ''' \n",
    "scores = cross_val_score(\n",
    "    pipeline_simple,\n",
    "    frequency_vectors,\n",
    "    df_processed_data[TARGET_VARIABLE], cv=10)\n",
    "print(\"Mean accuracy for explicit pipeline: \", scores.mean())\n",
    "\n",
    "scores = cross_val_score(\n",
    "    pipeline,\n",
    "    df_processed_data['PROCESSED_DOC'],\n",
    "    df_processed_data[TARGET_VARIABLE], cv=10)\n",
    "print(\"Mean accuracy for implicit pipeline: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Let's evaluate more deeply the best model '''\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_processed_data['LEMMATIZED_DOC'],\n",
    "    df_processed_data[TARGET_VARIABLE],\n",
    "    test_size=0.33, random_state=42)\n",
    "\n",
    "train1 = X_train.tolist()\n",
    "labelsTrain1 = y_train.tolist()\n",
    "test1 = X_test.tolist()\n",
    "labelsTest1 = y_test.tolist()\n",
    "\"\"\"  train \"\"\"\n",
    "pipeline.fit(train1, labelsTrain1)\n",
    "\"\"\"  test \"\"\"\n",
    "preds = pipeline.predict(test1)\n",
    "print(\"accuracy:\", accuracy_score(labelsTest1, preds))\n",
    "print(\n",
    "    classification_report(\n",
    "        labelsTest1,\n",
    "        preds,\n",
    "        target_names=df_processed_data[TARGET_VARIABLE].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better visualasing model classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 20))\n",
    "axes = plt.axes()\n",
    "\n",
    "print(plot_confusion_matrix(pipeline, preds, labelsTest1, cmap='hot', ax=axes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
